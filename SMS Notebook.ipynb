{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SML project - sms spam detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import re # regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import spam data and shaping it\n",
    "smsList = pd.read_table(\"SMSSpamCollection.txt\", header=None, names=['label', 'message'])\n",
    "\n",
    "smsList[\"label\"] = smsList[\"label\"].map({\"ham\":0,\"spam\":1})\n",
    "\n",
    "X = smsList.message\n",
    "y = smsList.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vect = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98851399856424982"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(X_train_vect, y_train)\n",
    "\n",
    "y_prediction_class = nb.predict(X_test_vect)\n",
    "\n",
    "metrics.accuracy_score(y_test, y_prediction_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### With 10-fold cross validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989247311828\n",
      "0.978494623656\n",
      "0.980251346499\n",
      "0.991023339318\n",
      "0.982046678636\n",
      "0.992818671454\n",
      "0.983842010772\n",
      "0.989228007181\n",
      "0.980251346499\n",
      "0.992818671454\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "for train_i, test_i in kf.split(X, y):\n",
    "    cv = CountVectorizer()\n",
    "    train_set = cv.fit_transform([X[i] for i in train_i])\n",
    "    train_class = [y[i] for i in train_i]\n",
    "    test_set = cv.transform([X[i] for i in test_i])\n",
    "    test_class = [y[i] for i in test_i]\n",
    "    nb.fit(train_set,train_class)\n",
    "    pred = nb.predict(test_set)\n",
    "    print(metrics.accuracy_score(test_class, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation neural network\n",
    "We're implementing the technique presented in this article :\n",
    "[RUAN, Guangchen et TAN, Ying. A three-layer back-propagation neural network for spam detection using artificial immune concentration. Soft computing, 2010, vol. 14, no 2, p. 139-150.](https://link.springer.com/content/pdf/10.1007%2Fs00500-009-0440-2.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGLISH_STOP_WORDS = frozenset([\n",
    "    \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\",\n",
    "    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
    "    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
    "    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
    "    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n",
    "    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
    "    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n",
    "    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n",
    "    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n",
    "    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n",
    "    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
    "    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\",\n",
    "    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n",
    "    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n",
    "    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
    "    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
    "    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
    "    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n",
    "    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
    "    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
    "    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
    "    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n",
    "    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
    "    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
    "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n",
    "    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
    "    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n",
    "    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n",
    "    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
    "    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n",
    "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n",
    "    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
    "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n",
    "    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n",
    "    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
    "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "    \"yourselves\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile('\\w+')\n",
    "words = {}\n",
    "N = 0 # number of non-spam\n",
    "S = 0 # number of spam\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\"\"\"count words support in spam and non-spam sms\n",
    "words['toto'][0] = number of non-spam sms containing the word 'toto'\n",
    "words['toto'][1] = number of spam sms containing the word 'toto'\n",
    "words['toto'][0] + words['toto'][1] = number of sms containing the word 'toto'\n",
    "\"\"\"\n",
    "for i in X_train.index:\n",
    "    X_train[i] = X_train[i].lower()\n",
    "    message = X_train[i]\n",
    "    spam = y_train[i]\n",
    "    # print(str(i) + \" (\" + str(spam) + \") - \" + message)\n",
    "    if spam == 0:\n",
    "        N += 1\n",
    "    else:\n",
    "        S += 1\n",
    "    messageWords = list(set(regex.findall(message))) # doesn't take duplicate\n",
    "    for word in messageWords:\n",
    "        if word in words:\n",
    "            words[word][spam] += 1\n",
    "        else:\n",
    "            words[word] = [(spam + 1) % 2, spam]\n",
    "\n",
    "# we only keep words that appears in less than 95% of sms\n",
    "genes = []\n",
    "for i in words:\n",
    "    if words[i][0] + words[i][1] >= 0.95 * len(X_train):\n",
    "        del words[i]\n",
    "    else:\n",
    "        words[i].append(words[i][0] / N) # frequency appearing in non-spam\n",
    "        words[i].append(words[i][1] / S) # frequency appearing in spam\n",
    "        words[i].append(words[i][2] - words[i][3]) # calculate \"proclivity\" Cf \"4.2 Generation of gene libraries\"\n",
    "        genes.append(i)\n",
    "    \n",
    "genes.sort(key = lambda a: -words[a][4])\n",
    "\n",
    "selfGenes = genes[:100]\n",
    "nonSelfGenes = genes[-100:]\n",
    "\n",
    "def getFeatures(message):\n",
    "    self = 0\n",
    "    nonSelf = 0\n",
    "    messageWords = list(set(regex.findall(message)))\n",
    "    for word in messageWords:\n",
    "        if word in selfGenes:\n",
    "            self += 1\n",
    "        elif word in nonSelfGenes:\n",
    "            nonSelf += 1\n",
    "    #return [self / max(1, len(messageWords)), nonSelf / max(1, len(messageWords))]\n",
    "    return [self, nonSelf] # got better results than the concentration proposed in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = []\n",
    "\n",
    "for message in X_train:\n",
    "    X_train_features.append(getFeatures(message))\n",
    "    \n",
    "X_test_features = []\n",
    "\n",
    "for message in X_test:\n",
    "    X_test_features.append(getFeatures(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957847533632287\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2), random_state=1, activation='logistic')\n",
    "clf.fit(X_train_features, y_train)\n",
    "\n",
    "test = clf.predict(X_test_features)\n",
    "correct = 0\n",
    "\n",
    "for i in range(len(test)):\n",
    "    if test[i] == y_test[X_test.index[i]]:\n",
    "        correct += 1\n",
    "        \n",
    "print(correct / len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([getFeatures('hey honey can u buy milk on your way home?')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([getFeatures('wanna win a new car? call this phone number asap 01245145624!!!')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
