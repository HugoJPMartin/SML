{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SML project - sms spam detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import re # regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import spam data and shaping it\n",
    "smsList = pd.read_table(\"SMSSpamCollection.txt\", header=None, names=['label', 'message'])\n",
    "\n",
    "smsList[\"label\"] = smsList[\"label\"].map({\"ham\":0,\"spam\":1})\n",
    "\n",
    "X = smsList.message\n",
    "y = smsList.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vect = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98851399856424982"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(X_train_vect, y_train)\n",
    "\n",
    "y_prediction_class = nb.predict(X_test_vect)\n",
    "\n",
    "metrics.accuracy_score(y_test, y_prediction_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### With 10-fold cross validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model):\n",
    "    kf = KFold(n_splits=10)\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for train_i, test_i in kf.split(X, y):\n",
    "        cv = CountVectorizer()\n",
    "\n",
    "        train_set = cv.fit_transform([X[i] for i in train_i])\n",
    "        train_class = [y[i] for i in train_i]\n",
    "\n",
    "        test_set = cv.transform([X[i] for i in test_i])\n",
    "        test_class = [y[i] for i in test_i]\n",
    "\n",
    "        model.fit(train_set,train_class)\n",
    "        pred = model.predict(test_set)\n",
    "        \n",
    "        r = metrics.accuracy_score(test_class, pred)\n",
    "        print(r)\n",
    "        res.append(r)\n",
    "        \n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989247311828\n",
      "0.978494623656\n",
      "0.980251346499\n",
      "0.991023339318\n",
      "0.982046678636\n",
      "0.992818671454\n",
      "0.983842010772\n",
      "0.989228007181\n",
      "0.980251346499\n",
      "0.992818671454\n",
      "Naive Bayes : 98.600220073% accuracy\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "nb_score = cross_val(nb)\n",
    "\n",
    "print(\"Naive Bayes : \" + str(nb_score*100) + \"% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation neural network\n",
    "We're implementing the technique presented in this article :\n",
    "[RUAN, Guangchen et TAN, Ying. A three-layer back-propagation neural network for spam detection using artificial immune concentration. Soft computing, 2010, vol. 14, no 2, p. 139-150.](https://link.springer.com/content/pdf/10.1007%2Fs00500-009-0440-2.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGLISH_STOP_WORDS = frozenset([\n",
    "    \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\",\n",
    "    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
    "    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
    "    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
    "    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n",
    "    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
    "    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n",
    "    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n",
    "    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n",
    "    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n",
    "    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
    "    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\",\n",
    "    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n",
    "    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n",
    "    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
    "    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
    "    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
    "    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n",
    "    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
    "    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
    "    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
    "    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n",
    "    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
    "    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
    "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n",
    "    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
    "    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n",
    "    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n",
    "    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
    "    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n",
    "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n",
    "    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
    "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n",
    "    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n",
    "    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
    "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "    \"yourselves\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile('\\w+')\n",
    "words = {}\n",
    "N = 0 # number of non-spam\n",
    "S = 0 # number of spam\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\"\"\"count words support in spam and non-spam sms\n",
    "words['toto'][0] = number of non-spam sms containing the word 'toto'\n",
    "words['toto'][1] = number of spam sms containing the word 'toto'\n",
    "words['toto'][0] + words['toto'][1] = number of sms containing the word 'toto'\n",
    "\"\"\"\n",
    "for i in X_train.index:\n",
    "    X_train[i] = X_train[i].lower()\n",
    "    message = X_train[i]\n",
    "    spam = y_train[i]\n",
    "    # print(str(i) + \" (\" + str(spam) + \") - \" + message)\n",
    "    if spam == 0:\n",
    "        N += 1\n",
    "    else:\n",
    "        S += 1\n",
    "    messageWords = list(set(regex.findall(message))) # doesn't take duplicate\n",
    "    for word in messageWords:\n",
    "        if word in words:\n",
    "            words[word][spam] += 1\n",
    "        else:\n",
    "            words[word] = [(spam + 1) % 2, spam]\n",
    "\n",
    "# we only keep words that appears in less than 95% of sms\n",
    "genes = []\n",
    "for i in words:\n",
    "    if words[i][0] + words[i][1] >= 0.95 * len(X_train):\n",
    "        del words[i]\n",
    "    else:\n",
    "        words[i].append(words[i][0] / N) # frequency appearing in non-spam\n",
    "        words[i].append(words[i][1] / S) # frequency appearing in spam\n",
    "        words[i].append(words[i][2] - words[i][3]) # calculate \"proclivity\" Cf \"4.2 Generation of gene libraries\"\n",
    "        genes.append(i)\n",
    "    \n",
    "genes.sort(key = lambda a: -words[a][4])\n",
    "\n",
    "selfGenes = genes[:round(len(genes) * 0.25)]\n",
    "nonSelfGenes = genes[-round(len(genes) * 0.25):]\n",
    "\n",
    "def getFeatures(message):\n",
    "    self = 0\n",
    "    nonSelf = 0\n",
    "    messageWords = list(set(regex.findall(message)))\n",
    "    for word in messageWords:\n",
    "        if word in selfGenes:\n",
    "            self += 1\n",
    "        elif word in nonSelfGenes:\n",
    "            nonSelf += 1\n",
    "    #return [self / max(1, len(messageWords)), nonSelf / max(1, len(messageWords))]\n",
    "    return [self, nonSelf] # got better results than the concentration proposed in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = []\n",
    "\n",
    "for message in X_train:\n",
    "    X_train_features.append(getFeatures(message))\n",
    "    \n",
    "X_test_features = []\n",
    "\n",
    "for message in X_test:\n",
    "    X_test_features.append(getFeatures(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9820627802690582\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(3), random_state=1, activation='logistic')\n",
    "clf.fit(X_train_features, y_train)\n",
    "\n",
    "test = clf.predict(X_test_features)\n",
    "correct = 0\n",
    "\n",
    "for i in range(len(test)):\n",
    "    if test[i] == y_test[X_test.index[i]]:\n",
    "        correct += 1\n",
    "        \n",
    "print(correct / len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([getFeatures('hey honey can u buy milk on your way home?')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([getFeatures('wanna win a new car? call this phone number asap 01245145624!!!')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "In this section we will test different SVM and analyse their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991039426523\n",
      "0.976702508961\n",
      "0.983842010772\n",
      "0.991023339318\n",
      "0.978456014363\n",
      "0.985637342908\n",
      "0.985637342908\n",
      "0.980251346499\n",
      "0.989228007181\n",
      "0.991023339318\n",
      "SVM with linear kernel : 98.5284067875% accuracy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvm = LinearSVC()\n",
    "\n",
    "#We use a 10 fold cross-validation to evaluate the SVM performance\n",
    "   \n",
    "score_linear = cross_val(lsvm)\n",
    "\n",
    "print(\"SVM with linear kernel : \" + str(score_linear*100) + \"% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856630824373\n",
      "0.84229390681\n",
      "0.876122082585\n",
      "0.870736086176\n",
      "0.870736086176\n",
      "0.883303411131\n",
      "0.868940754039\n",
      "0.850987432675\n",
      "0.868940754039\n",
      "0.870736086176\n",
      "SVM with polynomial kernel : 86.5942742418% accuracy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "psvm = SVC(kernel='poly')\n",
    "\n",
    "score_poly = cross_val(psvm)\n",
    "\n",
    "print(\"SVM with polynomial kernel : \" + str(score_poly*100) + \"% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856630824373\n",
      "0.84229390681\n",
      "0.876122082585\n",
      "0.870736086176\n",
      "0.870736086176\n",
      "0.883303411131\n",
      "0.868940754039\n",
      "0.850987432675\n",
      "0.868940754039\n",
      "0.870736086176\n",
      "SVM with rbf kernel : 86.5942742418% accuracy\n"
     ]
    }
   ],
   "source": [
    "rsvm = SVC(kernel='rbf')\n",
    "\n",
    "score_rbf = cross_val(rsvm)\n",
    "\n",
    "print(\"SVM with rbf kernel : \" + str(score_rbf*100) + \"% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with sigmoid kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856630824373\n",
      "0.84229390681\n",
      "0.876122082585\n",
      "0.870736086176\n",
      "0.870736086176\n",
      "0.883303411131\n",
      "0.868940754039\n",
      "0.850987432675\n",
      "0.868940754039\n",
      "0.870736086176\n",
      "SVM with sigmoid kernel : 86.5942742418% accuracy\n"
     ]
    }
   ],
   "source": [
    "ssvm = SVC(kernel='sigmoid')\n",
    "\n",
    "score_sigmoid = cross_val(ssvm)\n",
    "\n",
    "print(\"SVM with sigmoid kernel : \" + str(score_sigmoid*100) + \"% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM with a Linear kernel offer a good accuracy score of 98.52%, wich is good, even if on the same condition the Naive Bayes obtain 98.60% wich is a bit better.  \n",
    "The others SVM all obtain the same 86.59%, which is a bit odd as we use different kernels. It probably show that the spam detection problem is simple enough that learning anything more complicated than a linear function doesn't work well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.976702508961\n",
      "0.982078853047\n",
      "0.973070017953\n",
      "0.973070017953\n",
      "0.971274685817\n",
      "0.97486535009\n",
      "0.967684021544\n",
      "0.965888689408\n",
      "0.958707360862\n",
      "0.976660682226\n",
      "Decision Tree score : 97.2000218786% accuracy\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "t = tree.DecisionTreeClassifier()\n",
    "\n",
    "score_tree = cross_val(t)\n",
    "\n",
    "print(\"Decision Tree score : \" + str(score_tree*100) + \"% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree work pretty well, doing 97% accuracy on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
